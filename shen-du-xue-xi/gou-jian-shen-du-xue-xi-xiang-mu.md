## 计划

我们将开发分为四个阶段，最后三个阶段在多次迭代中进行。

- 项目研究
- 模型设计
- 实现及调试
- 实验及调参

需要把控的是：

- 快速实现第一版策略，后面的迭代才是真正花时间的地方。
- 多使用开源的、现成的东西，不要重复造轮子

## 数据集合

好的数据集合的特征:

- 类别均衡
- 数据充足
- 数据和标记中有高质量信息
- 数据和标记错误非常小
- 与你的问题相关

需要注意的问题：

- 关于类别平衡，实际上优先和问题同分布，不过不平衡相当影响神经网络的学习。
- 实验的时候不一定使用全量数据，耗时太长
- 收集足够的样本。如果样本不够，应考虑迁移学习。
- 有意识的迭代地样本，比如分析错误并过滤掉与实际问题无关的样本；

    数据没有好坏之分，只是有些数据不能满足你的需求。此外，随着样本类别的增加，训练和保持输出质量会变得更加困难，删除不相关的数据可以得到一个更好的模型。


## 设计细节

### 框架选择及成果复用

- 现在 tensorflow 还是主流。（2018-04）

- 尽量对前人的成果进行复用。比如使用别人 pre-train  embedding 


###  Cost function  成本函数的选择

并非所有的成本函数都是等价的，它会影响模型的训练难度。有些问题合适 成本函数的标准（默认），有些需要根据问题进行修改。

一些是一些简单原则：

- 分类问题：交叉熵，折页损失函数（SVM）
- 回归： 均方误差（MSE）
- 对象检测或分割：交并比（IoU）
- 策略优化：KL 散度
- 词嵌入：噪音对比估计（NCE）
- 词向量：余弦相似度

注意:

- 在理论分析中看起来不错的成本函数在实践中可能不太好用。
- 成本函数可以是部分猜测加部分实验，也可以是几个成本函数的组合。

### Metrics 度量标准

良好的度量标准有助于更好地比较和调整模型。

**技巧**：对于特殊问题，请查看 Kaggle 平台，该平台组织了许多 DL 竞赛，并提供了详细的度量标准。 

### Metrics 正则化


### 梯度下降

### 特征归一


### 批归一化和层归一化

### Dropout

### 激活函数

### 拆分数据集

### baseline

### 检查点